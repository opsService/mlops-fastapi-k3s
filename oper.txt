NEW_INFERENCE_TAG="final-debug-v1"
sudo nerdctl build -t localhost:5002/heedong/mlflow-inference-server:${NEW_INFERENCE_TAG} -f Dockerfile.inference .
sudo nerdctl push localhost:5002/heedong/mlflow-inference-server:${NEW_INFERENCE_TAG}
sudo crictl pull localhost:5002/heedong/mlflow-inference-server:${NEW_INFERENCE_TAG}

sudo nerdctl build -t localhost:5002/heedong/fastapi-mlops-api:latest -f Dockerfile.fastapi .
sudo nerdctl push localhost:5002/heedong/fastapi-mlops-api:latest
sudo crictl pull localhost:5002/heedong/fastapi-mlops-api:latest

sudo nerdctl build -t localhost:5002/heedong/mlflow-trainer:latest -f Dockerfile.traincpu .
sudo nerdctl push localhost:5002/heedong/mlflow-trainer:latest
sudo crictl pull localhost:5002/heedong/mlflow-trainer:latest

sudo rm -rf /mnt/opsops/data/minio/mlflow-artifacts
sudo rm -rf /mnt/opsops/data/postgresql/
sudo mkdir /mnt/opsops/data/postgresql
sudo chown 999 /mnt/opsops/data/postgresql/

kubectl port-forward svc/minio-service 9001:9001
kubectl port-forward svc/mlflow-tracking-service 5000:5000
kubectl port-forward service/fastapi-mlops-api-service 8000:8000 -n default